Capturing execution frames: sharp_basic.json
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-warning] WARNING: Multiple instances of Three.js being imported.
  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.
  Validating workflow...
  Queuing workflow for execution...
  Execution error: {'prompt_id': 'def9532e-59aa-41a5-8539-5e4a2e2df29d', 'node_id': '5', 'node_type': 'SharpPredict', 'executed': ['2', '1'], 'exception_message': 'Input type (float) and bias type (struct c10::BFloat16) should be the same\n', 'exception_type': 'RuntimeError', 'traceback': ['  File "G:\\ComfyUI\\execution.py", line 527, in execute\n    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "G:\\ComfyUI\\execution.py", line 331, in get_output_data\n    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "G:\\ComfyUI\\execution.py", line 305, in _async_map_node_over_list\n    await process_inputs(input_dict, i)\n', '  File "G:\\ComfyUI\\execution.py", line 293, in process_inputs\n    result = f(**inputs)\n', '  File "G:\\python\\Lib\\site-packages\\torch\\utils\\_contextlib.py", line 124, in decorate_context\n    return func(*args, **kwargs)\n', '  File "G:\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\predict.py", line 190, in predict\n    gaussians = self._predict_image_cached(\n        predictor, image_np, f_px, device,\n        extrinsics=img_extrinsics,\n        intrinsics=img_intrinsics,\n    )\n', '  File "G:\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\predict.py", line 284, in _predict_image_cached\n    monodepth_output, _ = predictor.encode(image_resized_pt)\n                          ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n', '  File "G:\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\predictor.py", line 112, in encode\n    monodepth_output = self.monodepth_model(image)\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "G:\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\monodepth.py", line 197, in forward\n    encoder_output = self.monodepth_predictor.encoder(inputs)\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "G:\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\encoders\\spn_encoder.py", line 249, in forward\n    x_pyramid_encodings, patch_intermediate_features = self.patch_encoder(x_pyramid_patches)\n                                                       ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "G:\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\encoders\\vit_encoder.py", line 70, in forward\n    x = self.patch_embed(input_tensor)\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "G:\\python\\Lib\\site-packages\\timm\\layers\\patch_embed.py", line 136, in forward\n    x = self.proj(x)\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\conv.py", line 553, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\conv.py", line 548, in _conv_forward\n    return F.conv2d(\n           ~~~~~~~~^\n        input, weight, bias, self.stride, self.padding, self.dilation, self.groups\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n'], 'current_inputs': {'focal_length_mm': [30], 'output_prefix': ['sharp'], 'model': ["{'model_path': 'G:\\\\ComfyUI\\\\models\\\\sharp\\\\sharp_2572gikvuh.pt', 'dtype': torch.bfloat16}"], 'image': ['tensor([[[[0.0039, 0.4863, 0.9608],\n          [0.0039, 0.4863, 0.9608],\n          [0.0039, 0.4863, 0.9608],\n          ...,\n          [0.0510, 0.0353, 0.0000],\n          [0.0510, 0.0353, 0.0000],\n          [0.0510, 0.0353, 0.0000]],\n\n         [[0.0039, 0.4863, 0.9608],\n          [0.0039, 0.4863, 0.9608],\n          [0.0039, 0.4863, 0.9608],\n          ...,\n          [0.0510, 0.0353, 0.0000],\n          [0.0510, 0.0353, 0.0000],\n          [0.0510, 0.0353, 0.0000]],\n\n         [[0.0039, 0.4863, 0.9608],\n          [0.0039, 0.4863, 0.9608],\n          [0.0039, 0.4863, 0.9608],\n          ...,\n          [0.0510, 0.0353, 0.0000],\n          [0.0510, 0.0353, 0.0000],\n          [0.0510, 0.0353, 0.0000]],\n\n         ...,\n\n         [[0.6824, 0.6157, 0.5373],\n          [0.6824, 0.6157, 0.5373],\n          [0.6824, 0.6157, 0.5373],\n          ...,\n          [0.5137, 0.4627, 0.4275],\n          [0.5137, 0.4627, 0.4314],\n          [0.5137, 0.4627, 0.4275]],\n\n         [[0.6824, 0.6157, 0.5373],\n          [0.6824, 0.6157, 0.5373],\n          [0.6824, 0.6157, 0.5373],\n          ...,\n          [0.5059, 0.4667, 0.4314],\n          [0.5059, 0.4627, 0.4392],\n          [0.5059, 0.4667, 0.4314]],\n\n         [[0.6824, 0.6157, 0.5373],\n          [0.6824, 0.6157, 0.5373],\n          [0.6824, 0.6157, 0.5373],\n          ...,\n          [0.5059, 0.4627, 0.4392],\n          [0.5059, 0.4627, 0.4392],\n          [0.5059, 0.4627, 0.4392]]]])']}, 'current_outputs': ['4', '2', '5', '1'], 'timestamp': 1771257122391}
    Status: FAILED
    Error: Workflow execution failed: {'prompt_id': 'def9532e-59aa-41a5-8539-5e4a2e2df29d', 'node_id': '5', 'node_type': 'SharpPredict', 'executed': ['2', '1'], 'exception_message': 'Input type (float) and bias type (struct c10::BFloat16) should be the same\n', 'exception_type': 'RuntimeError', 'traceback': ['  File "G:\\ComfyUI\\execution.py", line 527, in execute\n    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "G:\\ComfyUI\\execution.py", line 331, in get_output_data\n    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "G:\\ComfyUI\\execution.py", line 305, in _async_map_node_over_list\n    await process_inputs(input_dict, i)\n', '  File "G:\\ComfyUI\\execution.py", line 293, in process_inputs\n    result = f(**inputs)\n', '  File "G:\\python\\Lib\\site-packages\\torch\\utils\\_contextlib.py", line 124, in decorate_context\n    return func(*args, **kwargs)\n', '  File "G:\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\predict.py", line 190, in predict\n    gaussians = self._predict_image_cached(\n        predictor, image_np, f_px, device,\n        extrinsics=img_extrinsics,\n        intrinsics=img_intrinsics,\n    )\n', '  File "G:\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\predict.py", line 284, in _predict_image_cached\n    monodepth_output, _ = predictor.encode(image_resized_pt)\n                          ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n', '  File "G:\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\predictor.py", line 112, in encode\n    monodepth_output = self.monodepth_model(image)\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "G:\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\monodepth.py", line 197, in forward\n    encoder_output = self.monodepth_predictor.encoder(inputs)\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "G:\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\encoders\\spn_encoder.py", line 249, in forward\n    x_pyramid_encodings, patch_intermediate_features = self.patch_encoder(x_pyramid_patches)\n                                                       ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "G:\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\encoders\\vit_encoder.py", line 70, in forward\n    x = self.patch_embed(input_tensor)\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "G:\\python\\Lib\\site-packages\\timm\\layers\\patch_embed.py", line 136, in forward\n    x = self.proj(x)\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\conv.py", line 553, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "G:\\python\\Lib\\site-packages\\torch\\nn\\modules\\conv.py", line 548, in _conv_forward\n    return F.conv2d(\n           ~~~~~~~~^\n        input, weight, bias, self.stride, self.padding, self.dilation, self.groups\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n'], 'current_inputs': {'focal_length_mm': [30], 'output_prefix': ['sharp'], 'model': ["{'model_path': 'G:\\\\ComfyUI\\\\models\\\\sharp\\\\sharp_2572gikvuh.pt', 'dtype': torch.bfloat16}"], 'image': ['tensor([[[[0.0039, 0.4863, 0.9608],\n          [0.0039, 0.4863, 0.9608],\n          [0.0039, 0.4863, 0.9608],\n          ...,\n          [0.0510, 0.0353, 0.0000],\n          [0.0510, 0.0353, 0.0000],\n          [0.0510, 0.0353, 0.0000]],\n\n         [[0.0039, 0.4863, 0.9608],\n          [0.0039, 0.4863, 0.9608],\n          [0.0039, 0.4863, 0.9608],\n          ...,\n          [0.0510, 0.0353, 0.0000],\n          [0.0510, 0.0353, 0.0000],\n          [0.0510, 0.0353, 0.0000]],\n\n         [[0.0039, 0.4863, 0.9608],\n          [0.0039, 0.4863, 0.9608],\n          [0.0039, 0.4863, 0.9608],\n          ...,\n          [0.0510, 0.0353, 0.0000],\n          [0.0510, 0.0353, 0.0000],\n          [0.0510, 0.0353, 0.0000]],\n\n         ...,\n\n         [[0.6824, 0.6157, 0.5373],\n          [0.6824, 0.6157, 0.5373],\n          [0.6824, 0.6157, 0.5373],\n          ...,\n          [0.5137, 0.4627, 0.4275],\n          [0.5137, 0.4627, 0.4314],\n          [0.5137, 0.4627, 0.4275]],\n\n         [[0.6824, 0.6157, 0.5373],\n          [0.6824, 0.6157, 0.5373],\n          [0.6824, 0.6157, 0.5373],\n          ...,\n          [0.5059, 0.4667, 0.4314],\n          [0.5059, 0.4627, 0.4392],\n          [0.5059, 0.4667, 0.4314]],\n\n         [[0.6824, 0.6157, 0.5373],\n          [0.6824, 0.6157, 0.5373],\n          [0.6824, 0.6157, 0.5373],\n          ...,\n          [0.5059, 0.4627, 0.4392],\n          [0.5059, 0.4627, 0.4392],\n          [0.5059, 0.4627, 0.4392]]]])']}, 'current_outputs': ['4', '2', '5', '1'], 'timestamp': 1771257122391}
    Details: Workflow: G:\ComfyUI\custom_nodes\ComfyUI-Sharp\workflows\sharp_basic.json
Node error: SharpPredict