Capturing execution frames: sharp_exif.json
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-warning] WARNING: Multiple instances of Three.js being imported.
  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.
  Validating workflow...
  Queuing workflow for execution...
  Execution error: {'prompt_id': 'ed21c745-69af-45c7-a545-e784297b6ac1', 'node_id': '7', 'node_type': 'SharpPredict', 'executed': ['9', '2'], 'exception_message': 'Input type (float) and bias type (struct c10::BFloat16) should be the same\n', 'exception_type': 'RuntimeError', 'traceback': ['  File "F:\\ComfyUI_windows_portable\\ComfyUI\\execution.py", line 527, in execute\n    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\execution.py", line 331, in get_output_data\n    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\execution.py", line 305, in _async_map_node_over_list\n    await process_inputs(input_dict, i)\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\execution.py", line 293, in process_inputs\n    result = f(**inputs)\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\utils\\_contextlib.py", line 124, in decorate_context\n    return func(*args, **kwargs)\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\predict.py", line 190, in predict\n    gaussians = self._predict_image_cached(\n        predictor, image_np, f_px, device,\n        extrinsics=img_extrinsics,\n        intrinsics=img_intrinsics,\n    )\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\predict.py", line 284, in _predict_image_cached\n    monodepth_output, _ = predictor.encode(image_resized_pt)\n                          ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\predictor.py", line 112, in encode\n    monodepth_output = self.monodepth_model(image)\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\monodepth.py", line 197, in forward\n    encoder_output = self.monodepth_predictor.encoder(inputs)\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\encoders\\spn_encoder.py", line 249, in forward\n    x_pyramid_encodings, patch_intermediate_features = self.patch_encoder(x_pyramid_patches)\n                                                       ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\encoders\\vit_encoder.py", line 70, in forward\n    x = self.patch_embed(input_tensor)\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\timm\\layers\\patch_embed.py", line 136, in forward\n    x = self.proj(x)\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\conv.py", line 553, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\conv.py", line 548, in _conv_forward\n    return F.conv2d(\n           ~~~~~~~~^\n        input, weight, bias, self.stride, self.padding, self.dilation, self.groups\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n'], 'current_inputs': {'focal_length_mm': [20], 'output_prefix': ['sharp'], 'model': ["{'model_path': 'F:\\\\ComfyUI_windows_portable\\\\ComfyUI\\\\models\\\\sharp\\\\sharp_2572gikvuh.pt', 'dtype': torch.bfloat16}"], 'image': ['tensor([[[[0.2157, 0.1647, 0.1569],\n          [0.2275, 0.1608, 0.1608],\n          [0.2275, 0.1647, 0.1529],\n          ...,\n          [0.4471, 0.4745, 0.4863],\n          [0.4510, 0.4745, 0.4863],\n          [0.4431, 0.4745, 0.4745]],\n\n         [[0.2196, 0.1686, 0.1569],\n          [0.2314, 0.1647, 0.1608],\n          [0.2353, 0.1647, 0.1647],\n          ...,\n          [0.4549, 0.4784, 0.4706],\n          [0.4549, 0.4706, 0.4784],\n          [0.4431, 0.4706, 0.4667]],\n\n         [[0.2314, 0.1725, 0.1569],\n          [0.2510, 0.1725, 0.1608],\n          [0.2392, 0.1725, 0.1686],\n          ...,\n          [0.4588, 0.4745, 0.4627],\n          [0.4510, 0.4745, 0.4667],\n          [0.4471, 0.4706, 0.4627]],\n\n         ...,\n\n         [[0.1569, 0.1647, 0.1843],\n          [0.1647, 0.1725, 0.1882],\n          [0.1490, 0.1686, 0.1922],\n          ...,\n          [0.1020, 0.1137, 0.1373],\n          [0.1137, 0.1176, 0.1412],\n          [0.0863, 0.1176, 0.1373]],\n\n         [[0.1569, 0.1686, 0.1804],\n          [0.1569, 0.1647, 0.1961],\n          [0.1490, 0.1647, 0.1961],\n          ...,\n          [0.1059, 0.1216, 0.1294],\n          [0.1176, 0.1216, 0.1333],\n          [0.1059, 0.1137, 0.1373]],\n\n         [[0.1608, 0.1686, 0.1843],\n          [0.1608, 0.1686, 0.1882],\n          [0.1569, 0.1686, 0.1882],\n          ...,\n          [0.1059, 0.1176, 0.1333],\n          [0.1137, 0.1176, 0.1333],\n          [0.1333, 0.1176, 0.1333]]]])']}, 'current_outputs': ['9', '8', '2', '7'], 'timestamp': 1771257182827}
    Status: FAILED
    Error: Workflow execution failed: {'prompt_id': 'ed21c745-69af-45c7-a545-e784297b6ac1', 'node_id': '7', 'node_type': 'SharpPredict', 'executed': ['9', '2'], 'exception_message': 'Input type (float) and bias type (struct c10::BFloat16) should be the same\n', 'exception_type': 'RuntimeError', 'traceback': ['  File "F:\\ComfyUI_windows_portable\\ComfyUI\\execution.py", line 527, in execute\n    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\execution.py", line 331, in get_output_data\n    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\execution.py", line 305, in _async_map_node_over_list\n    await process_inputs(input_dict, i)\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\execution.py", line 293, in process_inputs\n    result = f(**inputs)\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\utils\\_contextlib.py", line 124, in decorate_context\n    return func(*args, **kwargs)\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\predict.py", line 190, in predict\n    gaussians = self._predict_image_cached(\n        predictor, image_np, f_px, device,\n        extrinsics=img_extrinsics,\n        intrinsics=img_intrinsics,\n    )\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\predict.py", line 284, in _predict_image_cached\n    monodepth_output, _ = predictor.encode(image_resized_pt)\n                          ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\predictor.py", line 112, in encode\n    monodepth_output = self.monodepth_model(image)\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\monodepth.py", line 197, in forward\n    encoder_output = self.monodepth_predictor.encoder(inputs)\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\encoders\\spn_encoder.py", line 249, in forward\n    x_pyramid_encodings, patch_intermediate_features = self.patch_encoder(x_pyramid_patches)\n                                                       ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "F:\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-Sharp\\nodes\\sharp\\models\\encoders\\vit_encoder.py", line 70, in forward\n    x = self.patch_embed(input_tensor)\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\timm\\layers\\patch_embed.py", line 136, in forward\n    x = self.proj(x)\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\conv.py", line 553, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n', '  File "F:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\conv.py", line 548, in _conv_forward\n    return F.conv2d(\n           ~~~~~~~~^\n        input, weight, bias, self.stride, self.padding, self.dilation, self.groups\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n'], 'current_inputs': {'focal_length_mm': [20], 'output_prefix': ['sharp'], 'model': ["{'model_path': 'F:\\\\ComfyUI_windows_portable\\\\ComfyUI\\\\models\\\\sharp\\\\sharp_2572gikvuh.pt', 'dtype': torch.bfloat16}"], 'image': ['tensor([[[[0.2157, 0.1647, 0.1569],\n          [0.2275, 0.1608, 0.1608],\n          [0.2275, 0.1647, 0.1529],\n          ...,\n          [0.4471, 0.4745, 0.4863],\n          [0.4510, 0.4745, 0.4863],\n          [0.4431, 0.4745, 0.4745]],\n\n         [[0.2196, 0.1686, 0.1569],\n          [0.2314, 0.1647, 0.1608],\n          [0.2353, 0.1647, 0.1647],\n          ...,\n          [0.4549, 0.4784, 0.4706],\n          [0.4549, 0.4706, 0.4784],\n          [0.4431, 0.4706, 0.4667]],\n\n         [[0.2314, 0.1725, 0.1569],\n          [0.2510, 0.1725, 0.1608],\n          [0.2392, 0.1725, 0.1686],\n          ...,\n          [0.4588, 0.4745, 0.4627],\n          [0.4510, 0.4745, 0.4667],\n          [0.4471, 0.4706, 0.4627]],\n\n         ...,\n\n         [[0.1569, 0.1647, 0.1843],\n          [0.1647, 0.1725, 0.1882],\n          [0.1490, 0.1686, 0.1922],\n          ...,\n          [0.1020, 0.1137, 0.1373],\n          [0.1137, 0.1176, 0.1412],\n          [0.0863, 0.1176, 0.1373]],\n\n         [[0.1569, 0.1686, 0.1804],\n          [0.1569, 0.1647, 0.1961],\n          [0.1490, 0.1647, 0.1961],\n          ...,\n          [0.1059, 0.1216, 0.1294],\n          [0.1176, 0.1216, 0.1333],\n          [0.1059, 0.1137, 0.1373]],\n\n         [[0.1608, 0.1686, 0.1843],\n          [0.1608, 0.1686, 0.1882],\n          [0.1569, 0.1686, 0.1882],\n          ...,\n          [0.1059, 0.1176, 0.1333],\n          [0.1137, 0.1176, 0.1333],\n          [0.1333, 0.1176, 0.1333]]]])']}, 'current_outputs': ['9', '8', '2', '7'], 'timestamp': 1771257182827}
    Details: Workflow: F:\ComfyUI_windows_portable\ComfyUI\custom_nodes\ComfyUI-Sharp\workflows\sharp_exif.json
Node error: SharpPredict